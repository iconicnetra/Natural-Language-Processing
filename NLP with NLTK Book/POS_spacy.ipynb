{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS with Spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the English tokenizer, tagger, parser, NER, and word vectors \n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\") #English model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Descriptive Narratives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DET'), ('ancient', 'ADJ'), ('tree', 'NOUN'), ('cast', 'VERB'), ('a', 'DET'), ('long', 'ADJ'), ('shadow', 'NOUN'), ('over', 'ADP'), ('the', 'DET'), ('old', 'ADJ'), (',', 'PUNCT'), ('crumbling', 'VERB'), ('wall', 'NOUN'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"The ancient tree cast a long shadow over the old, crumbling wall.\")\n",
    "\n",
    "print([(token.text, token.pos_) for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Simple Statements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DET'), ('cat', 'NOUN'), ('sleeps', 'VERB'), ('on', 'ADP'), ('the', 'DET'), ('warm', 'ADJ'), ('mat', 'NOUN'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"The cat sleeps on the warm mat.\")\n",
    "print([(token.text, token.pos_) for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('What', 'DET'), ('time', 'NOUN'), ('do', 'AUX'), ('we', 'PRON'), ('need', 'VERB'), ('to', 'PART'), ('leave', 'VERB'), ('for', 'ADP'), ('the', 'DET'), ('airport', 'NOUN'), ('?', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"What time do we need to leave for the airport?\")\n",
    "print([(token.text, token.pos_) for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Complex Sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('If', 'SCONJ'), (' ', 'SPACE'), ('it', 'PRON'), ('rains', 'VERB'), ('tomorrow', 'NOUN'), (',', 'PUNCT'), ('the', 'DET'), ('picnic', 'NOUN'), ('will', 'AUX'), ('be', 'AUX'), ('cancelled', 'VERB'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"If  it rains tomorrow, the picnic will be cancelled.\")\n",
    "print([(token.text, token.pos_) for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Use of Conjunction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('She', 'PRON'), ('plays', 'VERB'), ('the', 'DET'), ('guitar', 'NOUN'), ('and', 'CCONJ'), ('sings', 'NOUN'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"She plays the guitar and sings.\")\n",
    "print([(token.text, token.pos_) for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Future Tense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('They', 'PRON'), ('will', 'AUX'), ('start', 'VERB'), ('the', 'DET'), ('construction', 'NOUN'), ('next', 'ADP'), ('month', 'NOUN'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"They will start the construction next month.\")\n",
    "print([(token.text, token.pos_) for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: Past perfect Tense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('he', 'PRON'), ('had', 'AUX'), ('finished', 'VERB'), ('the', 'DET'), ('work', 'NOUN'), ('before', 'SCONJ'), ('the', 'DET'), ('boss', 'NOUN'), ('arrived', 'VERB'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"he had finished the work before the boss arrived.\")\n",
    "print([(token.text, token.pos_) for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 7: List items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Eggs', 'PROPN'), (',', 'PUNCT'), ('milk', 'NOUN'), (',', 'PUNCT'), ('bread', 'NOUN'), (',', 'PUNCT'), ('and', 'CCONJ'), ('butter', 'NOUN'), ('are', 'AUX'), ('on', 'ADP'), ('the', 'DET'), ('shopping', 'NOUN'), ('list', 'NOUN'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Eggs, milk, bread, and butter are on the shopping list.\")\n",
    "print([(token.text, token.pos_) for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 8: Adjective-heavy Sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DET'), ('old', 'ADJ'), ('wooen', 'NOUN'), ('cottage', 'NOUN'), ('stood', 'VERB'), ('alone', 'ADJ'), ('on', 'ADP'), ('the', 'DET'), ('hill', 'NOUN'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"The old wooen cottage stood alone on the hill.\")\n",
    "print([(token.text, token.pos_) for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 9: Technical Contents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Python', 'PROPN'), ('utilizes', 'VERB'), ('dynamic', 'ADJ'), ('typing', 'NOUN'), ('and', 'CCONJ'), ('manages', 'VERB'), ('memory', 'NOUN'), ('automatically', 'ADV'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Python utilizes dynamic typing and manages memory automatically.\")\n",
    "\n",
    "print([(token.text, token.pos_) for token in doc])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 10: Literary Style "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Beneath', 'ADP'), ('the', 'DET'), ('clear', 'ADJ'), ('sky', 'NOUN'), (',', 'PUNCT'), ('the', 'DET'), ('river', 'NOUN'), ('glittered', 'VERB'), ('under', 'ADP'), ('the', 'DET'), ('sun', 'NOUN'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Beneath the clear sky, the river glittered under the sun.\")\n",
    "print([(token.text, token.pos_) for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 11: Imperative Sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Close', 'VERB'), ('the', 'DET'), ('door', 'NOUN'), ('quitely', 'ADV'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Close the door quitely.\")\n",
    "print([(token.text, token.pos_) for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 12: Interrogative with Modal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Can', 'AUX'), ('you', 'PRON'), ('open', 'VERB'), ('the', 'DET'), ('window', 'NOUN'), ('?', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Can you open the window?\")\n",
    "print([(token.text, token.pos_) for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 13: Complex Compound Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRON'), ('ran', 'VERB'), ('to', 'ADP'), ('the', 'DET'), ('store', 'NOUN'), (',', 'PUNCT'), ('but', 'CCONJ'), ('they', 'PRON'), ('were', 'AUX'), ('out', 'ADP'), ('of', 'ADP'), ('milk', 'NOUN'), (',', 'PUNCT'), ('so', 'ADV'), ('I', 'PRON'), ('bought', 'VERB'), ('juice', 'NOUN'), ('insted', 'VERB'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I ran to the store, but they were out of milk, so I bought juice insted.\")\n",
    "print([(token.text, token.pos_) for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 14: Use of Passive Voice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DET'), ('book', 'NOUN'), ('was', 'AUX'), ('wirtten', 'ADJ'), ('by', 'ADP'), ('Netra', 'PROPN'), ('Kumar', 'PROPN'), ('Manandhar', 'PROPN'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"The book was wirtten by Netra Kumar Manandhar.\")\n",
    "\n",
    "print([(token.text, token.pos_) for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 15: Historical Facts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('In', 'ADP'), ('1991', 'NUM'), (',', 'PUNCT'), ('Kathmandu', 'PROPN'), ('was', 'AUX'), ('a', 'DET'), ('small', 'ADJ'), ('city', 'NOUN'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"In 1991, Kathmandu was a small city.\")\n",
    "print([(token.text, token.pos_) for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 16: Technical and Scientific Statement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Carbon', 'NOUN'), ('dioxide', 'NOUN'), ('levels', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('atmosphere', 'NOUN'), ('have', 'AUX'), ('risen', 'VERB'), ('dramatically', 'ADV'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Carbon dioxide levels in the atmosphere have risen dramatically.\")\n",
    "print([(token.text, token.pos_) for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 17: Conditional Sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('If', 'SCONJ'), ('you', 'PRON'), ('save', 'VERB'), ('oney', 'NOUN'), (',', 'PUNCT'), ('you', 'PRON'), ('can', 'AUX'), ('by', 'ADP'), ('a', 'DET'), ('new', 'ADJ'), ('laptop', 'NOUN'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"If you save oney, you can by a new laptop.\")\n",
    "print([(token.text, token.pos_) for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 18: Use of Infinitives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('To', 'PART'), ('understand', 'VERB'), ('recursion', 'NOUN'), (',', 'PUNCT'), ('one', 'PRON'), ('must', 'AUX'), ('first', 'ADV'), ('understand', 'VERB'), ('recursion', 'NOUN'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"To understand recursion, one must first understand recursion.\")\n",
    "print([(token.text, token.pos_) for token in doc])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 19: Statement with Gerunds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Swimming', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('ocean', 'NOUN'), ('has', 'AUX'), ('been', 'AUX'), ('Sharon', 'PROPN'), (\"'s\", 'PART'), ('passion', 'NOUN'), ('since', 'SCONJ'), ('she', 'PRON'), ('was', 'AUX'), ('five', 'NUM'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Swimming in the ocean has been Sharon's passion since she was five.\")\n",
    "print([(token.text, token.pos_) for token in doc])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 20: Complex Stentence with Multiple Clauses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('When', 'SCONJ'), ('I', 'PRON'), ('arrive', 'VERB'), (',', 'PUNCT'), ('if', 'SCONJ'), ('the', 'DET'), ('weather', 'NOUN'), ('is', 'AUX'), ('nice', 'ADJ'), (',', 'PUNCT'), ('we', 'PRON'), ('will', 'AUX'), ('go', 'VERB'), ('to', 'ADP'), ('the', 'DET'), ('park', 'NOUN'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"When I arrive, if the weather is nice, we will go to the park.\")\n",
    "print([(token.text, token.pos_) for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersanding which POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNP: noun, proper singular\n",
      "VBZ: verb, 3rd person singular present\n",
      "JJ: adjective (English), other noun-modifier (Chinese)\n",
      "RB: adverb\n",
      "IN: conjunction, subordinating or preposition\n",
      "SCONJ: subordinating conjunction\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the English NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Example tags\n",
    "tags = [\"NNP\", \"VBZ\", \"JJ\", \"RB\", \"IN\", \"SCONJ\"]\n",
    "\n",
    "# Print explanations for each tag\n",
    "for tag in tags:\n",
    "    print(f\"{tag}: {spacy.explain(tag)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple      PROPN - proper noun\n",
      "is         AUX   - auxiliary\n",
      "looking    VERB  - verb\n",
      "at         ADP   - adposition\n",
      "buying     VERB  - verb\n",
      "U.K.       PROPN - proper noun\n",
      "startup    NOUN  - noun\n",
      "for        ADP   - adposition\n",
      "$          SYM   - symbol\n",
      "1          NUM   - numeral\n",
      "billion    NUM   - numeral\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER, and word vectors\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process a sample text\n",
    "text = \"Apple is looking at buying U.K. startup for $1 billion\"\n",
    "doc = nlp(text)\n",
    "\n",
    "# Output tokens and their POS tags, and explain each tag\n",
    "for token in doc:\n",
    "    print(f\"{token.text:10} {token.pos_:5} - {spacy.explain(token.pos_)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
