{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love this book! 0.0\n",
      "It's so interesting and well-written. 0.0\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(\"I love this book! It's so interesting and well-written.\")\n",
    "\n",
    "for sent in doc.sents:\n",
    "    print(sent.text, sent.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'person': ['I'], 'place': ['Hattiban'], 'time': ['now', 'today', 'tomorrow']}\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "utterance = \"I work at KU now, today, tomorrow, and always at Hattiban.\"\n",
    "\n",
    "tokens = word_tokenize(utterance)\n",
    "\n",
    "person_deixis = ['I', 'me', 'my', 'mine', 'we', 'us', 'our', 'ours']\n",
    "place_deixis = ['here', 'there', 'where', 'Hattiban']   \n",
    "time_deixis = ['now', 'then', 'today', 'yesterday', 'tomorrow']\n",
    "\n",
    "deictic_words = {\n",
    "    \"person\": [],\n",
    "    \"place\": [], \n",
    "    \"time\": []\n",
    "}\n",
    "\n",
    "for token in tokens: \n",
    "    if token in person_deixis:\n",
    "        deictic_words[\"person\"].append(token)\n",
    "    elif token in place_deixis:\n",
    "        deictic_words[\"place\"].append(token)    \n",
    "    elif token in time_deixis:\n",
    "        deictic_words[\"time\"].append(token)\n",
    "\n",
    "print(deictic_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implicature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please close the window.\n"
     ]
    }
   ],
   "source": [
    "utterance = \"It's cold in here.\"\n",
    "\n",
    "def recognize_implicature(utterance):\n",
    "    if \"cold\" in utterance:\n",
    "        return \"Please close the window.\"\n",
    "    return \"No implicature detected.\"\n",
    "\n",
    "print(recognize_implicature(utterance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 0.0\n",
      "love 0.0\n",
      "this 0.0\n",
      "book 0.0\n",
      "! 0.0\n",
      "It 0.0\n",
      "'s 0.0\n",
      "so 0.0\n",
      "interesting 0.0\n",
      "and 0.0\n",
      "well 0.0\n",
      "- 0.0\n",
      "written 0.0\n",
      ". 0.0\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc = nlp(\"I love this book! It's so interesting and well-written.\")\n",
    "\n",
    "for token in doc: \n",
    "    print(token.text, token.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.18.0.post0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: nltk>=3.8 in e:\\python\\myenv\\lib\\site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in e:\\python\\myenv\\lib\\site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in e:\\python\\myenv\\lib\\site-packages (from nltk>=3.8->textblob) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\python\\myenv\\lib\\site-packages (from nltk>=3.8->textblob) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in e:\\python\\myenv\\lib\\site-packages (from nltk>=3.8->textblob) (4.66.2)\n",
      "Requirement already satisfied: colorama in e:\\python\\myenv\\lib\\site-packages (from click->nltk>=3.8->textblob) (0.4.6)\n",
      "Downloading textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
      "   ---------------------------------------- 0.0/626.3 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/626.3 kB ? eta -:--:--\n",
      "   -- ------------------------------------ 41.0/626.3 kB 653.6 kB/s eta 0:00:01\n",
      "   --------- ------------------------------ 153.6/626.3 kB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 378.9/626.3 kB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 626.3/626.3 kB 3.0 MB/s eta 0:00:00\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.18.0.post0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence sentiment: Sentiment(polarity=0.5625, subjectivity=0.55)\n",
      "I Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "love Sentiment(polarity=0.5, subjectivity=0.6)\n",
      "this Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "book Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "It Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "'s Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "so Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "interesting Sentiment(polarity=0.5, subjectivity=0.5)\n",
      "and Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "well-written Sentiment(polarity=0.0, subjectivity=0.0)\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "sentence = \"I love this book! It's so interesting and well-written.\"\n",
    "blob = TextBlob(sentence)\n",
    "\n",
    "# Get the sentiment of the entire sentence\n",
    "print(\"Sentence sentiment:\", blob.sentiment)\n",
    "\n",
    "# Get the sentiment of each token (word)\n",
    "for word in blob.words:\n",
    "    print(word, TextBlob(word).sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
